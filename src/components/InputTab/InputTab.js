import React, { useState, useContext } from 'react';
import { AppContext } from '../../context/AppContext';
import { callOpenRouterAPI } from '../../api/openRouterAPI';
import Button from '../common/Button';
import './InputTab.css';

const cleanOpicResponse = (rawText) => {
  if (!rawText) return '';
  const prefixesToRemove = [
    'Question:', 'Sample Answer:', 'Answer:',
    'C√¢u h·ªèi:', 'C√¢u tr·∫£ l·ªùi m·∫´u:', 'C√¢u tr·∫£ l·ªùi:'
  ];
  const cleanedLines = rawText.split('\n').map(line => {
    let cleanedLine = line.trim();
    for (const prefix of prefixesToRemove) {
      if (cleanedLine.toLowerCase().startsWith(prefix.toLowerCase())) {
        cleanedLine = cleanedLine.substring(prefix.length).trim();
        break;
      }
    }
    return cleanedLine;
  });
  return cleanedLines.join('\n').trim();
};


const InputTab = () => {
  const [isLoading, setIsLoading] = useState(false);
  const [selectedLevel, setSelectedLevel] = useState('AL');
  const { 
    setSentenceData,
    selectedModel, setSelectedModel, 
    setActiveTab,
    opicText, setOpicText
  } = useContext(AppContext);

  const handleFetchData = async () => {
    setIsLoading(true);
    let levelText = '';
    if (selectedLevel === 'IM') levelText = 'Intermediate Mid';
    else if (selectedLevel === 'IH') levelText = 'Intermediate High';
    else levelText = 'Advanced Low';
    const OPIC_PROMPT = `Give me one OPIC question and a sample answer at the ${selectedLevel} (${levelText}) level.\nThe answer should be 150‚Äì200 words, natural, fluent, and include personal details and storytelling.\nUse informal spoken English.\nOnly output the question and the answer. Do not include any introductions, labels, titles, or extra text.`;
    const result = await callOpenRouterAPI(OPIC_PROMPT, selectedModel || 'gpt-3.5-turbo');
    if (result && result.error) {
      let errorMsg = `L·ªói khi k·∫øt n·ªëi AI: ${result.message}`;
      if (result.status === 404 || (result.message && result.message.toLowerCase().includes('no endpoints'))) {
        errorMsg += '\nModel n√†y hi·ªán kh√¥ng kh·∫£ d·ª•ng. Vui l√≤ng ch·ªçn model kh√°c trong danh s√°ch.';
      } else if (result.status) {
        errorMsg = `L·ªói khi k·∫øt n·ªëi AI (m√£ ${result.status}): ${result.message}`;
      }
      setOpicText(errorMsg);
    } else {
      const cleanedText = cleanOpicResponse(result);
      setOpicText(cleanedText);
    }
    setIsLoading(false);
  };
  
  const handleProcessText = () => {
    const extractedSentences = opicText
      .split(/[.!?]+/)
      .map(s => s.trim())
      .filter(s => s.length > 10 && s.split(' ').length >= 5);
    if (extractedSentences.length === 0) return;
    const initialSentenceData = extractedSentences.map((text, index) => ({
      originalText: text,
      originalIndex: index,
      usedWords: []
    }));
    setSentenceData(initialSentenceData);
    setActiveTab('Luy·ªán t·∫≠p');
  };

  const models = [
    // C√°c model mi·ªÖn ph√≠ c·ªßa OpenRouter
    { id: 'gpt-3.5-turbo', name: 'OpenAI: GPT-3.5 Turbo (Mi·ªÖn ph√≠)' },
    { id: 'openchat/openchat-3.5-0106', name: 'OpenChat: OpenChat 3.5 (Mi·ªÖn ph√≠)' },
    { id: 'nous-hermes-2-vision', name: 'Nous Hermes 2 Vision (Mi·ªÖn ph√≠)' },
    { id: 'mistral/mistral-small', name: 'Mistral: Mistral Small (Mi·ªÖn ph√≠)' },
    { id: 'google/gemini-flash-1.5', name: 'Google: Gemini Flash 1.5 (Mi·ªÖn ph√≠)' },
    { id: 'google/gemini-flash-2', name: 'Google: Gemini Flash 2 (Mi·ªÖn ph√≠)' },
    { id: 'xai/grok-1', name: 'Grok 1 (Mi·ªÖn ph√≠)' },
    { id: 'xai/grok-1.5', name: 'Grok 1.5 (Mi·ªÖn ph√≠)' },
    { id: 'xai/grok-1.5v', name: 'Grok 1.5V (Mi·ªÖn ph√≠)' },
    { id: 'xai/grok-4', name: 'Grok 4 (Mi·ªÖn ph√≠)' },
    // C√°c model tr·∫£ ph√≠ ph·ªï bi·∫øn
    { id: 'openai/gpt-4o-mini', name: 'OpenAI: GPT-4o Mini (C√¢n b·∫±ng)' },
    { id: 'google/gemini-flash-1.5', name: 'Google: Gemini 1.5 Flash (Nhanh)' },
    { id: 'anthropic/claude-3.5-sonnet', name: 'Anthropic: Claude 3.5 Sonnet (M·∫°nh m·∫Ω)' },
  ];

  return (
    <div className="input-tab-container">
      <div className="model-selector">
        <label htmlFor="model-select">Ch·ªçn Model AI:</label>
        <select id="model-select" value={selectedModel} onChange={(e) => setSelectedModel(e.target.value)}>
          {models.map(model => <option key={model.id} value={model.id}>{model.name}</option>)}
        </select>
      </div>
      <div className="level-selector">
        <label htmlFor="level-select">Ch·ªçn Level:</label>
        <select id="level-select" value={selectedLevel} onChange={e => setSelectedLevel(e.target.value)}>
          <option value="IM">IM (Intermediate Mid)</option>
          <option value="IH">IH (Intermediate High)</option>
          <option value="AL">AL (Advanced Low)</option>
        </select>
      </div>
      <textarea value={opicText} onChange={(e) => setOpicText(e.target.value)} rows="8" placeholder="D√°n ƒëo·∫°n vƒÉn v√†o ƒë√¢y..."></textarea>
      <div className="button-group">
        <Button onClick={handleFetchData} disabled={isLoading}>
          {isLoading ? <div className="spinner"></div> : 'ü§ñ L·∫•y d·ªØ li·ªáu OPIC'}
        </Button>
        <Button onClick={handleProcessText} disabled={!opicText}>
          üìù B·∫Øt ƒë·∫ßu Luy·ªán t·∫≠p
        </Button>
      </div>
    </div>
  );
};

export default InputTab;